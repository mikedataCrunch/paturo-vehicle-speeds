{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91b6b14c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-12T15:48:52.765328Z",
     "start_time": "2021-09-12T15:48:52.440543Z"
    }
   },
   "source": [
    "# Preprocessing: Feature Engineering\n",
    "\n",
    "\n",
    "This notebook shows the steps to prepare raw gps data, building footprints data, administrative regions geospatial data, and road network data into files ready to be used in machine learning. These were all combined into processed `pandas.DataFrame()` stored in `../datasets/processed/`.\n",
    "\n",
    "The sections and the resulting features created by data from each section are as follows:\n",
    "1. Read GPS data files: `vehicle_id`, `dayofweek (0-7)`, `hour (0-23)`, `month (0-12)`, `instant_speed`, `datetime`, etc.\n",
    "2. Prepare road network data: `road_osmid`, `number_of_lanes`, `speed_limit_kph`, `road_segment_length`, `distance_to_road`\n",
    "3. Prepare barangay (administrative regions) info: `barangay`\n",
    "4. Prepare land-use profile data\n",
    "5. Feature engineering `multiprocessing` utils\n",
    "6. Run preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72047054",
   "metadata": {},
   "source": [
    "# Read GPS data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be46ea00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:45:58.322826Z",
     "start_time": "2022-05-24T13:45:48.619425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start_time = time()\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "import geopandas as gpd\n",
    "\n",
    "from datetime import datetime\n",
    "date = str(datetime.date(datetime.now()))\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fa9f53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:45:59.004669Z",
     "start_time": "2022-05-24T13:45:58.328177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:  /mnt/processed/private/paturo/Geospatial/data/gps_cache/route_cleaned/20210426-000000/123200872603.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54169 entries, 0 to 54168\n",
      "Data columns (total 26 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   time        54169 non-null  object \n",
      " 1   altitude    54169 non-null  int64  \n",
      " 2   angle       54169 non-null  int64  \n",
      " 3   speed       54169 non-null  int64  \n",
      " 4   accel       54169 non-null  int64  \n",
      " 5   ai1         54169 non-null  int64  \n",
      " 6   ai2         54169 non-null  int64  \n",
      " 7   ai3         54169 non-null  int64  \n",
      " 8   ai4         54169 non-null  int64  \n",
      " 9   alarm_code  54169 non-null  int64  \n",
      " 10  bats        54169 non-null  int64  \n",
      " 11  decel       54169 non-null  int64  \n",
      " 12  di1         54169 non-null  int64  \n",
      " 13  di2         54169 non-null  int64  \n",
      " 14  di3         54169 non-null  int64  \n",
      " 15  di4         54169 non-null  int64  \n",
      " 16  di5         54169 non-null  int64  \n",
      " 17  do1         54169 non-null  int64  \n",
      " 18  do2         54169 non-null  int64  \n",
      " 19  do3         54169 non-null  int64  \n",
      " 20  do4         54169 non-null  int64  \n",
      " 21  gpslev      54169 non-null  int64  \n",
      " 22  hdop        54169 non-null  float64\n",
      " 23  odo         54169 non-null  int64  \n",
      " 24  lon         54169 non-null  float64\n",
      " 25  lat         54169 non-null  float64\n",
      "dtypes: float64(3), int64(22), object(1)\n",
      "memory usage: 10.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# source of raw data from stops-API of the GPS provider\n",
    "# stops-API filters out data points with steady zero speed at time durations greater than 1 minute (c/o provider)\n",
    "gps_data_files = glob('/mnt/processed/private/paturo/Geospatial/data/gps_cache/route_cleaned/*/*.csv')\n",
    "\n",
    "# inspect filename info\n",
    "print(\"Filename: \", gps_data_files[0])\n",
    "\n",
    "# inspect contents\n",
    "display(pd.read_csv(gps_data_files[0]).info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ba0b19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:45:59.013258Z",
     "start_time": "2022-05-24T13:45:59.007068Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper function for imei extraction\n",
    "def _extract_imei(str_):\n",
    "    \"\"\"Extracts imei from path str\"\"\"\n",
    "    pattern = r\"([\\d]*)(?=\\.csv)\"\n",
    "    match = re.search(pattern, str_)\n",
    "    return match.group(0) # return imei\n",
    "\n",
    "def id_tagger(path):\n",
    "    \"\"\"Adds a vehicle id column extracted from source file IMEI name\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df['vehicle_id'] = _extract_imei(path)\n",
    "    return df\n",
    "\n",
    "def col_rename(df, rename_mapper):\n",
    "    \"\"\"Renames the columns according to preference\"\"\"\n",
    "    df = df.rename(columns=rename_mapper)\n",
    "    return df\n",
    "\n",
    "def nan_filter(df, usecols):\n",
    "    \"\"\"Filters rows according to important columns.\"\"\"\n",
    "    df = df.dropna(how='any', subset=usecols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aa756d",
   "metadata": {},
   "source": [
    "### Initial filtering from source [DONE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b130dc9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/660 [00:05<06:33,  1.66it/s]"
     ]
    }
   ],
   "source": [
    "# 6 min, done\n",
    "save_root = '../datasets/raw/'\n",
    "for path in tqdm(gps_data_files):\n",
    "    df = id_tagger(path)\n",
    "    df = col_rename(df, {'speed':'instant_speed',\n",
    "                         'time': 'datetime'})\n",
    "    df = nan_filter(df, ['lon', 'lat', 'instant_speed'])\n",
    "    dir_ = \"/\".join(path.split('/')[-3:-1])\n",
    "    save_dir = os.path.join(save_root, dir_)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    save_path = os.path.join(save_dir, _extract_imei(path)+'.csv')\n",
    "    df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f59b2d7",
   "metadata": {},
   "source": [
    "### Read filtered data from local data repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48340cd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.474Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_data_files = glob('../datasets/raw/route_cleaned/*/*.csv')\n",
    "df = pd.concat([pd.read_csv(path) for path in filtered_data_files])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784195c4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.475Z"
    }
   },
   "outputs": [],
   "source": [
    "vehicle_grouper = df.groupby('vehicle_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94525b58",
   "metadata": {},
   "source": [
    "## Prepare Road Network info: Cauayan Road Network\n",
    "\n",
    "### Adding more edge (road) data: `speed_kph` and `lanes`\n",
    "This section appends additional road data on maximum speed of a road and its number of lanes. Also, some cleaning is performed in cases where there are more than one `osmid`s tagged for a road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1944bc0f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.476Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def _clean_maxspeed(value, convert_mph=True):\n",
    "    try:\n",
    "        return float(value)\n",
    "\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "def _collapse_multiple_maxspeed_values(value, agg):\n",
    "    # if this isn't a list, just return it right back to the caller\n",
    "    if not isinstance(value, list):\n",
    "        return value\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            # clean each value in list and convert to kph if it is mph then\n",
    "            # return a single aggregated value\n",
    "            values = [x for x in value]\n",
    "            return int(agg(pd.Series(values).dropna().astype(int)))\n",
    "        except ValueError:\n",
    "            return None\n",
    "        \n",
    "def add_edge_lanes(G, hwy_lanes=None, fallback=None, precision=1, agg=np.median):\n",
    "\n",
    "    if fallback is None:\n",
    "        fallback = np.nan\n",
    "\n",
    "    edges = ox.graph_to_gdfs(G, nodes=False, fill_edge_geometry=False)\n",
    "\n",
    "    # collapse any highway lists (can happen during graph simplification)\n",
    "    # into string values simply by keeping just the first element of the list\n",
    "    edges[\"highway\"] = edges[\"highway\"].map(lambda x: x[0] if isinstance(x, list) else x)\n",
    "\n",
    "    if \"lanes\" in edges.columns:\n",
    "        # collapse any maxspeed lists (can happen during graph simplification)\n",
    "        # into a single value\n",
    "        edges[\"lanes\"] = edges[\"lanes\"].apply(_collapse_multiple_maxspeed_values, agg=agg)\n",
    "        \n",
    "        # create speed_kph by cleaning maxspeed strings and converting mph to\n",
    "        # kph if necessary\n",
    "        edges[\"lanes\"] = edges[\"lanes\"].astype(str).map(_clean_maxspeed).astype(float)\n",
    "    else:\n",
    "        # if no edges in graph had a maxspeed attribute\n",
    "        edges[\"lanes\"] = None\n",
    "\n",
    "    # if user provided hwy_lanes, use them as default values, otherwise\n",
    "    # initialize an empty series to populate with values\n",
    "    if hwy_lanes is None:\n",
    "        hwy_lane_avg = pd.Series(dtype=float)\n",
    "    else:\n",
    "        hwy_lane_avg = pd.Series(hwy_lanes).dropna()\n",
    "\n",
    "    # for each highway type that caller did not provide in hwy_lanes, impute\n",
    "    # numlanes of type by taking the mode of the preexisting lane values of that\n",
    "    # highway type\n",
    "    for hwy, group in edges.groupby(\"highway\"):\n",
    "        if hwy not in hwy_lane_avg:\n",
    "            hwy_lane_avg.loc[hwy] = agg(group[\"lanes\"])\n",
    "\n",
    "    # if any highway types had no preexisting lane values, impute their lane\n",
    "    # with fallback value provided by caller. if fallback=np.nan, impute lane\n",
    "    # as the mode lane of all highway types that did have preexisting values\n",
    "    hwy_lane_avg = hwy_lane_avg.fillna(fallback).fillna(agg(hwy_lane_avg))\n",
    "\n",
    "    # for each edge missing speed data, assign it the imputed value for its\n",
    "    # highway type\n",
    "    lanes = (\n",
    "        edges[[\"highway\", \"lanes\"]].set_index(\"highway\").iloc[:, 0].fillna(hwy_lane_avg)\n",
    "    )\n",
    "\n",
    "    # all speeds will be null if edges had no preexisting maxspeed data and\n",
    "    # caller did not pass in hwy_lanes or fallback arguments\n",
    "    if pd.isnull(lanes).all():\n",
    "        raise ValueError(\n",
    "            (\n",
    "                \"this graph's edges have no preexisting `maxspeed` \"\n",
    "                \"attribute values so you must pass `hwy_lanes` or \"\n",
    "                \"`fallback` arguments.\"\n",
    "            )\n",
    "        )\n",
    "    # add speed kph attribute to graph edges\n",
    "    edges[\"lanes\"] = lanes.round(precision).values\n",
    "    \n",
    "    # set values dict format as required by nx.set_edge_attributes()\n",
    "#     values = edges.set_index(['u', 'v', 'key'])['lanes'].to_dict() # 9091\n",
    "    values = edges['lanes'].to_dict() # 9092\n",
    "    nx.set_edge_attributes(G, values=values, name=\"lanes\")\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9abeb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.478Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '/mnt/processed/private/paturo/data/processed/graphs/cauayan.pickle'\n",
    "\n",
    "with open(path, 'rb') as handle:\n",
    "    G = pickle.load(handle)\n",
    "\n",
    "hwy_speeds = {\n",
    "    'trunk': 80, # most untagged values are near away from city center\n",
    "    'primary': 40,\n",
    "    'secondary': 30, # unpaved!!! dirt roads\n",
    "    'tertiary': 30,\n",
    "    'residential': 20,\n",
    "    'unclassified': 20   \n",
    "}\n",
    "\n",
    "hwy_lanes = {\n",
    "    'trunk': 2, # conservative guess\n",
    "    'primary': 1,\n",
    "    'secondary': 1,\n",
    "    'tertiary': 1,\n",
    "    'residential': 1,\n",
    "    'unclassified': 1   \n",
    "}\n",
    "\n",
    "G = ox.speed.add_edge_speeds(G, hwy_speeds=hwy_speeds, fallback=None, precision=1)\n",
    "G = add_edge_lanes(G, hwy_lanes=hwy_lanes, fallback=None, precision=1)\n",
    "\n",
    "# inspect the road network data\n",
    "nodes, edges = ox.graph_to_gdfs(G)\n",
    "edges.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb9da0",
   "metadata": {},
   "source": [
    "### Projection: `G` to `P` and initialization of `edges_df`\n",
    "\n",
    "In this section we take the same road network of Cauayan (`G`) from the previous preprocessing step of adding road speed data and project it to `P` having a CRS suitable for our vehicle gps coordinates format (EPSG:4326)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae49a18",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.479Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8302af0f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.480Z"
    }
   },
   "outputs": [],
   "source": [
    "from osmnx import projection\n",
    "\n",
    "# put crs into road_network (previously no crs)\n",
    "G.crs = \"EPSG:32651\"\n",
    "\n",
    "# project to epsg:4326 to suit lon lat for use in RUN section\n",
    "P = ox.projection.project_graph(G, to_crs=\"epsg:4326\")\n",
    "\n",
    "# used in tagging road data to vehicle\n",
    "edges_df = ox.graph_to_gdfs(P, nodes=False) # 9092 use only this line\n",
    "# edges_df = edges_df.set_index(['u', 'v', 'key']) # 9091"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939cb101",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.481Z"
    }
   },
   "outputs": [],
   "source": [
    "edges_df.info() # available road data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b192ecc",
   "metadata": {},
   "source": [
    "## Prepare Barangay info: `admin.zip` Polygons\n",
    "\n",
    "This section uses polygon data of barangays in Cauayan City to identify the barangay a vehicle is currently in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada7723",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.482Z"
    }
   },
   "outputs": [],
   "source": [
    "root = '/mnt/processed/private/paturo/Geospatial/preprocessing'\n",
    "\n",
    "admin_bounds_file = os.path.join(root, \"admin.zip\")\n",
    "admin_df = gpd.read_file(admin_bounds_file)\n",
    "admin_df.at[12, \"Brgy_Name\"] = \"Carabatan Bacareno\"\n",
    "\n",
    "# used in tagging vehicle to a barangay\n",
    "barangay_polygons = admin_df[['Brgy_Name', 'geometry']]\n",
    "admin_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e078002",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.483Z"
    }
   },
   "outputs": [],
   "source": [
    "admin_df.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4e990",
   "metadata": {},
   "source": [
    "## Prepare Land-use profile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436ceba",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.484Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import multiprocessing as mp\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6d522",
   "metadata": {},
   "source": [
    "### Visualization of raster and city boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac125a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.485Z"
    }
   },
   "outputs": [],
   "source": [
    "raster_root = '../datasets/raster-data/'\n",
    "hgt_file = \"N16E121.hgt\"\n",
    "src_path = os.path.join(raster_root, hgt_file)\n",
    "src = rasterio.open(src_path, driver=\"SRTMHGT\")\n",
    "\n",
    "bounds_path = os.path.join(raster_root, 'bounds.pkl')\n",
    "boundaries = pd.read_pickle(bounds_path)\n",
    "                     \n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "show(src, ax=ax)\n",
    "plt.colorbar(ax.images[0])\n",
    "boundaries.boundary.plot(ax=ax, color='yellow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad53c24",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.486Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_value(coords, src):\n",
    "    \"\"\"Return elevation from src\"\"\"\n",
    "    \n",
    "    if type(coords) != list:\n",
    "        coords = [coords]\n",
    "    return next(src.sample(coords))[0]\n",
    "\n",
    "def get_building_counts(row, src, buffer, building_types):\n",
    "    \"\"\"Return pixel count of a building class within a buffer\"\"\"\n",
    "    geometry = row.geometry.buffer(buffer) # buffer points by the meters (ensure data is projected)\n",
    "    out_image, out_transform = mask(src, [geometry], all_touched=True, crop=True)\n",
    "    for key, val in building_types.items():\n",
    "        row[key] = np.sum(out_image==val)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2311a7e",
   "metadata": {},
   "source": [
    "## Feature Engineering Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3793c4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.489Z"
    }
   },
   "outputs": [],
   "source": [
    "from osmnx.distance import nearest_edges\n",
    "\n",
    "def mp_tag_road_data(chunk, P, interpolate_dist, edges_df, road_cols):\n",
    "    \"\"\"Return df (chunk) with road network data corresponding to road_cols\n",
    "    plus distance_to_road.\n",
    "    \"\"\"\n",
    "    nearest_edge, distances = nearest_edges(\n",
    "        P, \n",
    "        chunk['lon'], chunk['lat'],\n",
    "        interpolate=interpolate_dist/6.371e6,\n",
    "        return_dist=True,\n",
    "    )\n",
    "    road_data = edges_df.loc[nearest_edge, road_cols]\n",
    "    chunk = pd.concat(\n",
    "        [chunk.reset_index(drop=True), road_data.reset_index(drop=True)],\n",
    "        axis=1\n",
    "    )\n",
    "    chunk['distance_to_road'] = distances\n",
    "    return chunk\n",
    "\n",
    "def mp_tag_brgy_data(chunk, barangay_polygons):\n",
    "    \"\"\"Return df (chunk) with new column: barangay, corresponding to brgy name\"\"\"\n",
    "    temp = chunk[['lon', 'lat']]\n",
    "    vehicle_coords = gpd.GeoDataFrame(temp, geometry=gpd.points_from_xy(temp.lon, temp.lat))\n",
    "    vehicle_coords.crs = \"epsg:4326\"\n",
    "    chunk['barangay'] = gpd.sjoin(\n",
    "        vehicle_coords, barangay_polygons, \n",
    "        how='left', \n",
    "        op='within')['Brgy_Name']\n",
    "    chunk['barangay'] = chunk['barangay'].fillna('Out-of-town')\n",
    "    return chunk\n",
    "    \n",
    "def mp_create_datetime_cols(chunk, datetime_col):\n",
    "    \"\"\"Create hour, dayofweek, and month columns form datetime col.\"\"\"\n",
    "    # Adding datetime cat cols\n",
    "    chunk['datetime'] = pd.to_datetime(chunk['datetime'])\n",
    "    chunk['hour'] = chunk[datetime_col].dt.hour\n",
    "    chunk['dayofweek'] = chunk[datetime_col].dt.dayofweek\n",
    "    chunk['month'] = chunk[datetime_col].dt.month\n",
    "    return chunk\n",
    "\n",
    "def mp_elevation(gdf_chunk):\n",
    "    \"\"\"Calculate and add elevation data for chunk.\"\"\"\n",
    "    raster_root = '../datasets/raster-data/'\n",
    "    hgt_file = \"N16E121.hgt\"\n",
    "    src_path = os.path.join(raster_root, hgt_file)\n",
    "    src = rasterio.open(src_path, driver=\"SRTMHGT\")\n",
    "    gdf_chunk['elevation'] = gdf_chunk.apply(lambda row: get_value((row.geometry.x, row.geometry.y), src), axis=1)\n",
    "    return gdf_chunk\n",
    "\n",
    "def mp_building_counts(gdf_chunk, tiff_file):\n",
    "    \"\"\"Calculate and add area of surrounding building type (in pixels)\"\"\"\n",
    "    raster_root = '../datasets/raster-data/'\n",
    "    tiff_tag = tiff_file.split('-')[-1].split('.')[0]\n",
    "    \n",
    "    building_types = {\n",
    "        f'pix_business_{tiff_tag}': 1,\n",
    "        f'pix_residential_{tiff_tag}': 2,\n",
    "        f'pix_industrial_{tiff_tag}': 3,\n",
    "        f'pix_institutional_{tiff_tag}': 4\n",
    "    }\n",
    "    \n",
    "    footprints_path = os.path.join(raster_root, tiff_file)\n",
    "    with rasterio.open(footprints_path) as src:\n",
    "        gdf_chunk = gdf_chunk.to_crs(25393).apply(\n",
    "            lambda x: get_building_counts(\n",
    "                x, src, buffer=200, building_types=building_types), axis=1)\n",
    "    return gdf_chunk\n",
    "\n",
    "def parallelize_pandas(df, func, *args):\n",
    "    cpus = mp.cpu_count()\n",
    "    df_chunks = np.array_split(df, cpus)\n",
    "    pool = mp.Pool(processes=cpus)\n",
    "    chunk_processes = [pool.apply_async(func, args=(chunk,*args)) for chunk in df_chunks]\n",
    "    df_results = []\n",
    "    for chunk in chunk_processes:\n",
    "        res = chunk.get()\n",
    "        df_results.append(res)\n",
    "    df_out = pd.concat(df_results)\n",
    "    return df_out\n",
    "\n",
    "def parallelize_geopandas(gdf, func, *args):\n",
    "    \"\"\"Parallelize functions used to get elevation and surrounding land-use area\"\"\"\n",
    "    cpus = mp.cpu_count()\n",
    "    gdf_chunks = np.array_split(gdf, cpus)\n",
    "    pool = mp.Pool(processes=cpus)\n",
    "    chunk_processes = [pool.apply_async(func, args=(chunk,*args)) for chunk in gdf_chunks]\n",
    "    gdf_results = []\n",
    "    for chunk in chunk_processes:\n",
    "        res = chunk.get()\n",
    "        res = res.to_crs(25393)\n",
    "        gdf_results.append(res)\n",
    "    gdf_out = gpd.GeoDataFrame(pd.concat(gdf_results))\n",
    "    return gdf_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e8dc72",
   "metadata": {},
   "source": [
    "## RUN: Parallelized Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dca44a",
   "metadata": {},
   "source": [
    "### Running per vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce20d87",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.490Z"
    }
   },
   "outputs": [],
   "source": [
    "def col_rename(df, rename_mapper):\n",
    "    \"\"\"Renames the columns according to preference\"\"\"\n",
    "    df = df.rename(columns=rename_mapper)\n",
    "    return df\n",
    "\n",
    "rename_mapper = {\n",
    "    'osmid': 'road_osmid',\n",
    "    'lanes': 'number_of_lanes',\n",
    "    'speed_kph': 'speed_limit_kph',\n",
    "    'length': 'road_segment_length',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe7bc1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.491Z"
    }
   },
   "outputs": [],
   "source": [
    "vehicle_grouper = df.groupby('vehicle_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b2e8f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:48.492Z"
    }
   },
   "outputs": [],
   "source": [
    "# for inspection only\n",
    "for name, group in tqdm(vehicle_grouper):\n",
    "    group = parallelize_pandas(group, mp_tag_road_data, P, 40, edges_df, ['osmid', 'lanes', 'speed_kph', 'length'])\n",
    "    group = parallelize_pandas(group, mp_tag_brgy_data, barangay_polygons)\n",
    "    group = group[group['barangay'] != 'Out-of-town']\n",
    "    group = parallelize_pandas(group, mp_create_datetime_cols, 'datetime')\n",
    "    \n",
    "    gdf = gpd.GeoDataFrame(group, geometry=gpd.points_from_xy(group.lon, group.lat))\n",
    "    gdf.crs = \"epsg:4326\"\n",
    "    gdf = parallelize_geopandas(gdf, mp_elevation)\n",
    "    gdf = parallelize_geopandas(gdf, mp_building_counts, 'footprints-4x4.tiff')\n",
    "    \n",
    "    group = pd.DataFrame(gdf.drop('geometry', axis=1))\n",
    "    group = col_rename(group, rename_mapper)\n",
    "    \n",
    "    save_dir = f'..datasets/processed/{date}'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    group.to_csv(os.path.join(save_dir, str(name)) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e35675",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:45:51.487Z"
    }
   },
   "outputs": [],
   "source": [
    "end_time = time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "print(f\"PREPROCESSING TIME: {duration/3600} Hrs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de92ad53",
   "metadata": {},
   "source": [
    "### One go [Kills Jojie Kernel]\n",
    "\n",
    "This section runs the entire pre-processing pipeline using a `multiprocessing` approach on the full dataset. Consequently, writing to file is done per group according to a per-vehicle id grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554f5d8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:27:05.241Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# pandas\n",
    "processed_df = parallelize_pandas(df, mp_tag_road_data, P, 40, edges_df, ['osmid', 'lanes', 'speed_kph', 'length'])\n",
    "processed_df = parallelize_pandas(processed_df, mp_tag_brgy_data, barangay_polygons)\n",
    "processed_df = processed_df[processed_df['barangay'] != 'Out-of-town'] # filter out points outside cauayan city\n",
    "processed_df = parallelize_pandas(processed_df, mp_create_datetime_cols, 'time')\n",
    "\n",
    "# geopandas\n",
    "processed_gdf = gpd.GeoDataFrame(processed_df, geometry=gpd.points_from_xy(group.lon, group.lat))\n",
    "processed_gdf.crs = \"epsg:4326\"\n",
    "processed_gdf = parallelize_geopandas(processed_gdf, mp_elevation)\n",
    "processed_gdf = parallelize_geopandas(processed_gdf, mp_building_counts, 'footprints-4x4.tiff')\n",
    "\n",
    "processed_df = pd.DataFrame(processed_gdf.drop('geometry', axis=1))\n",
    "processed_df = col_rename(processed_df, rename_mapper)\n",
    "processed_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3293bce6",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a857467",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:27:17.630Z"
    }
   },
   "outputs": [],
   "source": [
    "vehicle_grouper = processed_df.groupby('vehicle_id')\n",
    "\n",
    "for name, group in vehicle_grouper:\n",
    "    save_dir = f'..datasets/processed/{date}'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    group.to_csv(os.path.join(save_dir, str(name)) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9e15b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-24T13:27:20.382Z"
    }
   },
   "outputs": [],
   "source": [
    "end_time = time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "print(f\"PREPROCESSING TIME: {duration/3600} Hrs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7435673",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
