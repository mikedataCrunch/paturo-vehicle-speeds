{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0cd253b",
   "metadata": {},
   "source": [
    "# Vehicle Speed Aggregation: Moving Average Strategy\n",
    "\n",
    "* save directory: `../datasets/per-vehicle-moving-average/<aggregation type>/window-<some window choice>-<datestring>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed0a7060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T06:50:35.235883Z",
     "start_time": "2022-05-24T06:50:35.226813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import optuna\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import multiprocessing as mp\n",
    "from datetime import datetime\n",
    "date = str(datetime.date(datetime.now()))\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78506b37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T06:31:08.001394Z",
     "start_time": "2022-05-24T06:31:07.995597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM: 251.79 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "    \n",
    "ram_gb = psutil.virtual_memory().total / 2**30 # total physical memory in bytes\n",
    "print(f\"RAM: {ram_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3f8af6",
   "metadata": {},
   "source": [
    "## Read from source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "312b6cf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T06:34:06.507218Z",
     "start_time": "2022-05-24T06:31:33.933080Z"
    }
   },
   "outputs": [],
   "source": [
    "# read\n",
    "data_monthdate = '0328' # new data\n",
    "test = pd.read_csv(f'../datasets/ncc_{data_monthdate}_lgb_test.csv')\n",
    "train = pd.read_csv(f'../datasets/ncc_{data_monthdate}_lgb_train.csv')\n",
    "retrain = pd.read_csv(f'../datasets/ncc_{data_monthdate}_lgb_retrain.csv')\n",
    "df = pd.concat([test, train, retrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02944889",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T06:48:48.032592Z",
     "start_time": "2022-05-24T06:46:53.070462Z"
    }
   },
   "outputs": [],
   "source": [
    "# get datetime index\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.sort_values(by='time')\n",
    "df = df.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8109d620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T06:49:10.071962Z",
     "start_time": "2022-05-24T06:49:10.064333Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_periods(row, ref_index, thresh):\n",
    "    \"\"\"Return period counts for thresh\"\"\"\n",
    "    timedeltas = (row.name - ref_index).total_seconds()\n",
    "    # >= 0 includes self\n",
    "    periods = np.sum((timedeltas <= thresh) & (timedeltas >= 0))\n",
    "    return periods\n",
    "\n",
    "def get_agg_speed(row, group, thresh, agg='mean'):\n",
    "    \"\"\"Return a aggregated speed value according to thresh and agg.\"\"\"\n",
    "    timedeltas = (row.name - group.index).total_seconds()\n",
    "    mask = (timedeltas <= thresh) & (timedeltas >= 0)\n",
    "    # >= 0 includes self\n",
    "    if agg=='mean':\n",
    "        return group[mask]['vehicle_speed'].mean()\n",
    "    elif agg=='median':\n",
    "        return group[mask]['vehicle_speed'].median()    \n",
    "    else:\n",
    "        raise \"Enter valid agg.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc4480a",
   "metadata": {},
   "source": [
    "## Parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a505cb2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T06:49:26.464717Z",
     "start_time": "2022-05-24T06:49:26.448245Z"
    }
   },
   "outputs": [],
   "source": [
    "def mp_get_periods(chunk, ref_index, thresh):\n",
    "    chunk['num_periods'] = chunk.apply(\n",
    "        lambda row: get_periods(row, ref_index, thresh=thresh), axis=1)\n",
    "    return chunk\n",
    "\n",
    "def mp_agg_speed(chunk, full_df, thresh, agg):\n",
    "    chunk['agg_speed'] = chunk.apply(\n",
    "        lambda row: get_agg_speed(row, full_df, thresh=thresh, agg=agg), axis=1)\n",
    "    return chunk\n",
    "\n",
    "# parallelize agg function\n",
    "def parallelize_get_periods(df, func, thresh):\n",
    "    \"\"\"Parallelize mp_elevation and mp_building_counts functions\"\"\"\n",
    "    ref_index = df.index\n",
    "    cpus = mp.cpu_count()\n",
    "    df_chunks = np.array_split(df, cpus)\n",
    "    pool = mp.Pool(processes=cpus)\n",
    "    chunk_processes = [pool.apply_async(func, args=(chunk, ref_index, thresh)) for chunk in df_chunks]\n",
    "    df_results = []\n",
    "    for chunk in chunk_processes:\n",
    "        res = chunk.get()\n",
    "        df_results.append(res)\n",
    "    df_out = pd.concat(df_results)\n",
    "    return df_out\n",
    "\n",
    "def parallelize_agg_speed(df, func, thresh, agg):\n",
    "    cpus = mp.cpu_count()\n",
    "    df_chunks = np.array_split(df, cpus)\n",
    "    pool = mp.Pool(processes=cpus)\n",
    "    chunk_processes = [pool.apply_async(func, args=(chunk, df, thresh, agg)) for chunk in df_chunks]\n",
    "    df_results = []\n",
    "    for chunk in chunk_processes:\n",
    "        res = chunk.get()\n",
    "        df_results.append(res)\n",
    "    df_out = pd.concat(df_results)\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62805f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_vehicle_grouper = df.groupby('vehicle_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03b52285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T06:51:23.062807Z",
     "start_time": "2022-05-24T06:50:39.956823Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/199 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60335 entries, 0 to 60334\n",
      "Data columns (total 27 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   time             60335 non-null  datetime64[ns]\n",
      " 1   altitude         60335 non-null  float64       \n",
      " 2   vehicle_speed    60335 non-null  float64       \n",
      " 3   accel            60335 non-null  float64       \n",
      " 4   decel            60335 non-null  float64       \n",
      " 5   lon              60335 non-null  float64       \n",
      " 6   lat              60335 non-null  float64       \n",
      " 7   vehicle_id       60335 non-null  int64         \n",
      " 8   osmid            60335 non-null  object        \n",
      " 9   lanes            60335 non-null  float64       \n",
      " 10  speed_kph        60335 non-null  float64       \n",
      " 11  length           60335 non-null  float64       \n",
      " 12  dist_to_edge     60335 non-null  float64       \n",
      " 13  barangay         60335 non-null  object        \n",
      " 14  hour             60335 non-null  int64         \n",
      " 15  dayofweek        60335 non-null  int64         \n",
      " 16  month            60335 non-null  int64         \n",
      " 17  residential      60335 non-null  int64         \n",
      " 18  institutional    60335 non-null  int64         \n",
      " 19  industrial       60335 non-null  int64         \n",
      " 20  commercial       60335 non-null  int64         \n",
      " 21  elevation        60335 non-null  int64         \n",
      " 22  pix_business     60335 non-null  int64         \n",
      " 23  pix_residential  60335 non-null  int64         \n",
      " 24  pix_industrial   60335 non-null  int64         \n",
      " 25  num_periods      60335 non-null  int64         \n",
      " 26  agg_speed        60335 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(11), int64(13), object(2)\n",
      "memory usage: 12.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/199 [00:40<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "## use this for progress_apply method:\n",
    "# tqdm.pandas()\n",
    "\n",
    "lookback_window = 60 # seconds, can be changed\n",
    "agg = 'mean'\n",
    "# recompute speed through \"moving average\" method, get median/mean speed in window\n",
    "# saves a new csv with columns for number of periods (num_periods) and agg vehicle speed (agg_speed)\n",
    "\n",
    "for name, group in tqdm(per_vehicle_grouper):\n",
    "    \n",
    "    group = parallelize_get_periods(\n",
    "        df=group, \n",
    "        func=mp_get_periods, \n",
    "        thresh=lookback_window)\n",
    "    \n",
    "    group = parallelize_agg_speed(\n",
    "        df=group, \n",
    "        func=mp_agg_speed, \n",
    "        thresh=lookback_window, \n",
    "        agg=agg) \n",
    "    \n",
    "    group = group.reset_index()\n",
    "    display(group.info())\n",
    "    \n",
    "    break\n",
    "    \n",
    "    # prep paths\n",
    "    save_dir = f'datasets/per-vehicle-moving-average/{agg}/window-{window}-{date}'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    save_file = os.path.join(save_dir, f\"{name}.csv\")\n",
    "    \n",
    "    # save\n",
    "    group.to_csv(save_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b63334",
   "metadata": {},
   "source": [
    "## Serial Run (refactored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f72559f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-23T09:29:58.894Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/199 [5:17:42<37:21:23, 751.30s/it] "
     ]
    }
   ],
   "source": [
    "## use this for progress_apply method:\n",
    "# tqdm.pandas()\n",
    "\n",
    "window = 60 # seconds, can be changed\n",
    "agg = 'mean'\n",
    "\n",
    "per_vehicle_grouper = df.groupby('vehicle_id')\n",
    "\n",
    "# recompute speed through \"moving average\" method, get median speed in window\n",
    "# saves a new csv with columns for number of periods and agg vehicle speed\n",
    "for name, group in tqdm(per_vehicle_grouper):\n",
    "    ref_index = group.index\n",
    "    group['num_periods'] = group.apply(\n",
    "        lambda row: get_periods(row, ref_index, thresh=window), axis=1)\n",
    "    group['recomputed_speed'] = group.apply(\n",
    "        lambda row: get_agg_speed(row, group, thresh=window, agg='mean'), axis=1)\n",
    "    \n",
    "    # prep paths\n",
    "    save_dir = f'../dataset/per-vehicle-moving-average/{agg}/window-{window}'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    save_file = os.path.join(save_dir, f\"{name}.csv\")\n",
    "    \n",
    "    # save\n",
    "    group = group.reset_index()\n",
    "    group.to_csv(save_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588468ab",
   "metadata": {},
   "source": [
    "# Space-time Agg Strategy (Not done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_monthdate = '0328' # new data\n",
    "test = pd.read_csv(f'dataset/ncc_{data_monthdate}_lgb_test.csv')\n",
    "train = pd.read_csv(f'dataset/ncc_{data_monthdate}_lgb_train.csv')\n",
    "retrain = pd.read_csv(f'dataset/ncc_{data_monthdate}_lgb_retrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c6225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([test, train, retrain])\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.sort_values(by='time')\n",
    "df = df.set_index('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ccb529",
   "metadata": {},
   "source": [
    "## Code Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84cc2057",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:31:35.545129Z",
     "start_time": "2022-04-16T08:31:34.497840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb_retrain.csv\t\t  ncc_0325_lgb_train.csv    ncc_1118_lgb_test.csv\r\n",
      "lgb_test.csv\t\t  ncc_0328_lgb_retrain.csv  ncc_1118_lgb_train.csv\r\n",
      "lgb_train.csv\t\t  ncc_0328_lgb_test.csv     ncc_1120_lgb_retrain.csv\r\n",
      "ncc_0325_lgb_retrain.csv  ncc_0328_lgb_train.csv    ncc_1120_lgb_test.csv\r\n",
      "ncc_0325_lgb_test.csv\t  ncc_1118_lgb_retrain.csv  ncc_1120_lgb_train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1583c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test group for functions\n",
    "window = 120 # seconds\n",
    "for name, group in per_vehicle_grouper:\n",
    "    timedeltas = (group.iloc[2].name - group.index).total_seconds()\n",
    "    periods = np.sum((timedeltas <= window) & (timedeltas >= 0))\n",
    "    print(\"Periods: \", periods)\n",
    "\n",
    "    mask = (timedeltas <= window) & (timedeltas >= 0)\n",
    "    print(\"Agg speed: \", group[mask]['vehicle_speed'].median())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering prior to ML\n",
    "def filter_data(df):\n",
    "    df = df[df['dist_to_edge'] <= 20]\n",
    "    df = df[df['accel'] <= 20]\n",
    "    df = df[df['decel'] <= 20]\n",
    "    df['barangay'] = df['barangay'].fillna('Out-of-town')\n",
    "    df['lanes'] = df['lanes'].fillna(1.0)\n",
    "\n",
    "    # WATCH THIS: 60 (determine the percentile of 60kph in speed dist) reasonable na trike \n",
    "    df = df[df['vehicle_speed'] <= 60] # CHANGE TO 60\n",
    "    df = df[df['elevation'] <= 148] # based on cauayan city highest elevation in meters. (32 to 148 range)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
